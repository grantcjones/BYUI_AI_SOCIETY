{
    "sourceFile": "Week 1 - Text input and output/Ollama.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 8,
            "patches": [
                {
                    "date": 1738188528450,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1738188753961,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -92,14 +92,6 @@\n input(\"--------------------------------------------------------------------------------------------------------\")\r\n clear()\r\n \r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n-#?    What context looks like\r\n-#--------------------------------------------------------------------------------------------------------------------------------------------\r\n-\r\n-input(\"Press any key to save the context from earlier saved to context.json \")\r\n-with open('context.json', 'w') as f:\r\n-    json.dump(context, f)\r\n-\r\n-#--------------------------------------------------------------------------------------------------------------------------------------------\r\n #?   End of\r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n"
                },
                {
                    "date": 1738188762777,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -39,8 +39,16 @@\n input(\"--------------------------------------------------------------------------------------------------------\")\r\n clear()\r\n \r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n+#?    What context looks like\r\n+#--------------------------------------------------------------------------------------------------------------------------------------------\r\n+\r\n+input(\"Press any key to save the context from earlier saved to context.json \")\r\n+with open('context.json', 'w') as f:\r\n+    json.dump(context, f)\r\n+\r\n+#--------------------------------------------------------------------------------------------------------------------------------------------\r\n #?    Streamed text (to process it word by word as it generates)\r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n \r\n # A data stream is a type of data in Python where information is given piece by piece as it comes in.\r\n"
                },
                {
                    "date": 1738188772472,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,8 +42,9 @@\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n #?    What context looks like\r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n \r\n+context = output.context\r\n input(\"Press any key to save the context from earlier saved to context.json \")\r\n with open('context.json', 'w') as f:\r\n     json.dump(context, f)\r\n \r\n"
                },
                {
                    "date": 1738188781552,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -43,9 +43,9 @@\n #?    What context looks like\r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n \r\n context = output.context\r\n-input(\"Press any key to save the context from earlier saved to context.json \")\r\n+input(\"Press any key to  saved to context.json \")\r\n with open('context.json', 'w') as f:\r\n     json.dump(context, f)\r\n \r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n"
                },
                {
                    "date": 1738188788169,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -43,9 +43,9 @@\n #?    What context looks like\r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n \r\n context = output.context\r\n-input(\"Press any key to  saved to context.json \")\r\n+input(\"Press any key to save the context to context.json \")\r\n with open('context.json', 'w') as f:\r\n     json.dump(context, f)\r\n \r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n"
                },
                {
                    "date": 1738188842545,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -44,9 +44,9 @@\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n \r\n context = output.context\r\n input(\"Press any key to save the context to context.json \")\r\n-with open('context.json', 'w') as f:\r\n+with open('Week 2 - Using context/context.json', 'w') as f:\r\n     json.dump(context, f)\r\n \r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n #?    Streamed text (to process it word by word as it generates)\r\n"
                },
                {
                    "date": 1738188855478,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -44,9 +44,9 @@\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n \r\n context = output.context\r\n input(\"Press any key to save the context to context.json \")\r\n-with open('Week 2 - Using context/context.json', 'w') as f:\r\n+with open('Week 1 - Text input and output/context.json', 'w') as f:\r\n     json.dump(context, f)\r\n \r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n #?    Streamed text (to process it word by word as it generates)\r\n"
                },
                {
                    "date": 1738188885621,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,8 +46,9 @@\n context = output.context\r\n input(\"Press any key to save the context to context.json \")\r\n with open('Week 1 - Text input and output/context.json', 'w') as f:\r\n     json.dump(context, f)\r\n+clear()\r\n \r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n #?    Streamed text (to process it word by word as it generates)\r\n #--------------------------------------------------------------------------------------------------------------------------------------------\r\n"
                }
            ],
            "date": 1738188528450,
            "name": "Commit-0",
            "content": "#--------------------------------------------------------------------------------------------------------------------------------------------\r\n#?    Dependancies + Globals\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\nimport json                             # For context demonstration. This isn't important for AI.\r\nimport ollama\r\nMODEL = \"llama3.2:3B\"                   # The model we'll be using.\r\nPROMPT = \"write a very short story\"     # The prompt we'll be giving the AI.\r\n\r\nfrom simplify import clear              # Not important either. This just clears the terminal.\r\n\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n#?    Loading a model\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n#! The AI will take a bit to initialize before it actually starts generating something. It only has to do this\r\n#! once, but it'll turn off after about five minutes of no activity and have to be initialized again.\r\n\r\n#* This is for demonstating how long model loading takes.\r\nprint(\"Loading model...\")\r\noutput = ollama.generate(MODEL, 'Output just the word \"done\"')\r\ninput(\"Done.\")\r\nclear()\r\n\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n#?    Just the text. You won't see anything happen until all text has been generated.\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n# A token is the way the language model stores and computes text. Each token is a set of numbers, as demonstrated later.\r\n\r\ninput(\"Press any key to start generating a story (just the text).\")\r\nclear()\r\n\r\nprint(\"--------------------------------------------------------------------------------------------------------\")\r\n\r\noutput = ollama.generate(MODEL, PROMPT) # This takes over the main thread, stopping the program until it's done.\r\nprint(output.response)\r\n\r\ninput(\"--------------------------------------------------------------------------------------------------------\")\r\nclear()\r\n\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n#?    Streamed text (to process it word by word as it generates)\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n# A data stream is a type of data in Python where information is given piece by piece as it comes in.\r\n# This is used for things like microphone input or something being broadcasted from the internet.\r\n# These \"pieces\" are called chunks.\r\n\r\ninput(\"Press any key to start generating a story (as a stream).\")\r\nclear()\r\n\r\n# \"stream = True\" makes the output a datastream instead of a string. \r\n# This means Ollama is going to give you tokens as they generate instead of a piece of text all at once.\r\n\r\noutput = ollama.generate(MODEL, PROMPT, stream = True)\r\n\r\n# You'll notice that even though the output is labeled as \"stream\", code can still execute.\r\n# This is the case until you set it up to start reading the stream.\r\n\r\nprint(\"This can still happen even though generation has started.\")\r\n\r\nprint(\"--------------------------------------------------------------------------------------------------------\")\r\n\r\ncontext = []                                         #* Declare the context variable\r\nfull_text = ''                                       #* Start with an empty string\r\n\r\nfor chunk in output:                           #  This takes over the main thread, stopping any other execution.\r\n    text_from_data = chunk.response            #  This is where the text is stored, .response\r\n    full_text += text_from_data                      #* Add to the empty string\r\n    print(chunk.response, end='', flush=True)  #* Print the new text to the same line, not a new one\r\n    try:\r\n        context = chunk.context # Only the last chunk has context. This is how you would store it.\r\n    except:\r\n        \"\"\r\n\r\nprint(\"\\n--------------------------------------------------------------------------------------------------------\")\r\n\r\n\r\ninput(\"This executes when the stream doesn't have any data to give the loop. Once you start the for loop, nothing else can happen until generation is done..\")\r\nclear()\r\n\r\n#---------------------------------------------------\r\n#?    What you captured with \"full_text\"\r\n#---------------------------------------------------\r\n\r\ninput('Press any key to see what the empty \"full_text\" string has become.')\r\nclear()\r\n\r\nprint(\"--------------------------------------------------------------------------------------------------------\")\r\nprint(full_text)\r\ninput(\"--------------------------------------------------------------------------------------------------------\")\r\nclear()\r\n\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n#?    What context looks like\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\ninput(\"Press any key to save the context from earlier saved to context.json \")\r\nwith open('context.json', 'w') as f:\r\n    json.dump(context, f)\r\n\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n#?   End of\r\n#--------------------------------------------------------------------------------------------------------------------------------------------\r\n"
        }
    ]
}