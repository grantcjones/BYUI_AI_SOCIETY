{
    "sourceFile": "Week 2 - Using context/Ollama.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1737596784037,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1737666807473,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,9 +5,9 @@\n import json                               # For context demonstration. This isn't important for AI.\r\n import ollama\r\n MODEL = \"llama3.2\"                        # The model we'll be using.\r\n \r\n-from simplify import clear                # Not important either. This just clears the terminal.\r\n+from simplify import clear                # Not importanteither. This just clears the terminal.\r\n \r\n #--------------------------------------------------------------------------------------------------------------\r\n #?    Just the text. You won't see anything happen until all text has been generated.\r\n #--------------------------------------------------------------------------------------------------------------\r\n"
                },
                {
                    "date": 1738188506762,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -5,9 +5,9 @@\n import json                               # For context demonstration. This isn't important for AI.\r\n import ollama\r\n MODEL = \"llama3.2\"                        # The model we'll be using.\r\n \r\n-from simplify import clear                # Not importanteither. This just clears the terminal.\r\n+from simplify import clear                # Not important. This just clears the terminal.\r\n \r\n #--------------------------------------------------------------------------------------------------------------\r\n #?    Just the text. You won't see anything happen until all text has been generated.\r\n #--------------------------------------------------------------------------------------------------------------\r\n@@ -44,9 +44,9 @@\n #?    A review of what the looks like\r\n #--------------------------------------------------------------------------------------------------------------\r\n \r\n input(\"Press any key to save the context from earlier saved to context.json \")\r\n-with open('Week 2 - Demonstration/context.json', 'w') as f:\r\n+with open('context.json', 'w') as f:\r\n     json.dump(this_context, f)\r\n \r\n #--------------------------------------------------------------------------------------------------------------\r\n #     End of\r\n"
                },
                {
                    "date": 1738188801027,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -44,9 +44,9 @@\n #?    A review of what the looks like\r\n #--------------------------------------------------------------------------------------------------------------\r\n \r\n input(\"Press any key to save the context from earlier saved to context.json \")\r\n-with open('context.json', 'w') as f:\r\n+with open('Week 2 - Using context/context.json', 'w') as f:\r\n     json.dump(this_context, f)\r\n \r\n #--------------------------------------------------------------------------------------------------------------\r\n #     End of\r\n"
                },
                {
                    "date": 1738189013473,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,53 @@\n+#--------------------------------------------------------------------------------------------------------------\r\n+#?    Dependancies + Globals\r\n+#--------------------------------------------------------------------------------------------------------------\r\n+\r\n+import json                               # For context demonstration. This isn't important for AI.\r\n+import ollama\r\n+MODEL = \"llama3.2\"                        # The model we'll be using.\r\n+\r\n+from simplify import clear                # Not important. This just clears the terminal.\r\n+\r\n+#--------------------------------------------------------------------------------------------------------------\r\n+#?    Just the text. You won't see anything happen until all text has been generated.\r\n+#--------------------------------------------------------------------------------------------------------------\r\n+\r\n+print(\"--------------------------------------------------------------------------------------------------------\")\r\n+\r\n+\r\n+prompt = \"What's 5+5?\"\r\n+print(prompt)\r\n+\r\n+print(\"--------------------------------------------------------------------------------------------------------\")\r\n+\r\n+output = ollama.generate(MODEL, prompt)\r\n+this_context = output.context                                   #* This is where you grab its memory\r\n+print(output.response)\r\n+\r\n+input(\"--------------------------------------------------------------------------------------------------------\")\r\n+clear()\r\n+\r\n+print(\"--------------------------------------------------------------------------------------------------------\")\r\n+\r\n+prompt = \"Add another 5 to that.\"\r\n+print(prompt)\r\n+\r\n+print(\"--------------------------------------------------------------------------------------------------------\")\r\n+\r\n+output = ollama.generate(MODEL, prompt, context=this_context)  #* This is where you USE its memory\r\n+print(output.response)\r\n+\r\n+input(\"--------------------------------------------------------------------------------------------------------\")\r\n+clear()\r\n+\r\n+#--------------------------------------------------------------------------------------------------------------\r\n+#?    A review of what the context looks like\r\n+#--------------------------------------------------------------------------------------------------------------\r\n+\r\n+input(\"Press any key to save the context from earlier saved to context.json \")\r\n+with open('Week 2 - Using context/context.json', 'w') as f:\r\n+    json.dump(this_context, f)\r\n+\r\n+#--------------------------------------------------------------------------------------------------------------\r\n+#     End of\r\n+#--------------------------------------------------------------------------------------------------------------\r\n"
                }
            ],
            "date": 1737596784037,
            "name": "Commit-0",
            "content": "#--------------------------------------------------------------------------------------------------------------\r\n#?    Dependancies + Globals\r\n#--------------------------------------------------------------------------------------------------------------\r\n\r\nimport json                               # For context demonstration. This isn't important for AI.\r\nimport ollama\r\nMODEL = \"llama3.2\"                        # The model we'll be using.\r\n\r\nfrom simplify import clear                # Not important either. This just clears the terminal.\r\n\r\n#--------------------------------------------------------------------------------------------------------------\r\n#?    Just the text. You won't see anything happen until all text has been generated.\r\n#--------------------------------------------------------------------------------------------------------------\r\n\r\nprint(\"--------------------------------------------------------------------------------------------------------\")\r\n\r\n\r\nprompt = \"What's 5+5?\"\r\nprint(prompt)\r\n\r\nprint(\"--------------------------------------------------------------------------------------------------------\")\r\n\r\noutput = ollama.generate(MODEL, prompt)\r\nthis_context = output.context                                   #* This is where you grab its memory\r\nprint(output.response)\r\n\r\ninput(\"--------------------------------------------------------------------------------------------------------\")\r\nclear()\r\n\r\nprint(\"--------------------------------------------------------------------------------------------------------\")\r\n\r\nprompt = \"Add another 5 to that.\"\r\nprint(prompt)\r\n\r\nprint(\"--------------------------------------------------------------------------------------------------------\")\r\n\r\noutput = ollama.generate(MODEL, prompt, context=this_context)  #* This is where you USE its memory\r\nprint(output.response)\r\n\r\ninput(\"--------------------------------------------------------------------------------------------------------\")\r\nclear()\r\n\r\n#--------------------------------------------------------------------------------------------------------------\r\n#?    A review of what the looks like\r\n#--------------------------------------------------------------------------------------------------------------\r\n\r\ninput(\"Press any key to save the context from earlier saved to context.json \")\r\nwith open('Week 2 - Demonstration/context.json', 'w') as f:\r\n    json.dump(this_context, f)\r\n\r\n#--------------------------------------------------------------------------------------------------------------\r\n#     End of\r\n#--------------------------------------------------------------------------------------------------------------\r\n"
        }
    ]
}